{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77e825de-a6d8-4bd0-a9f7-0502a073f1af",
   "metadata": {},
   "source": [
    "# Data: Sources and Nature\n",
    "Sources of sentiment analysis include both structured (e.g., survey responses) and unstructured data (e.g., social media posts). Structured data typically comes from organized databases and spreadsheets whereas unstructured data originates from text documents, audio files, images, videos, and web pages. Unstructured data often requires extensive preprocessing before being fed into a sentiment analysis model because it contains noise, irrelevant content, spelling errors, typos, abbreviations, misspellings, acronyms, idioms, slang, jargon, sarcasm, and multiple languages. Preprocessed unstructured data may then be transformed into numerical values called features, vectors or scores representing each instance's polarity or valence (positive vs. negative) depending on the underlying sentiment analysis algorithm. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc3b346-6244-49c0-87e6-b44ea674b297",
   "metadata": {},
   "source": [
    "Other examples of sources for sentiment analysis include CRM records, phone calls, chat logs, email threads, support tickets, customer complaints, help desk requests, employee feedback, website clickstream, transactional history, and purchase intent signals. Some algorithms require additional metadata beyond the raw input text itself; these metadata may come from external application program interface (APIs) or APIs built specifically for sentiment analysis purposes, e.g., named entity recognition APIS."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e181ed28-8310-4977-b08b-9e93740cd681",
   "metadata": {},
   "source": [
    "In customer relationship management,for example, companies might need customer's opinions on a specific feature of a product or of the product itself. Writing text might take time and need effort. Leveraging on speech recognition models where customers can speek infront of their phones and the text is stored in CRMs, which in tern is an input to another model for sentiment analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3136c073-9ba0-4ac4-b062-19cf360afbcb",
   "metadata": {},
   "source": [
    "## Social Media and APIs \n",
    "There are several ways to extract data from social media platforms like Twitter and Facebook using APIs. To access tweet data, one needs to create an account on the official developer portal - <https://developer.twitter.com/>. From here you can sign up for API keys, create projects, view usage statistics, and set rate limits. Once registered, developers can retrieve tweets using standard HTTP requests with query parameters containing keywords, hashtags, handles, geolocation coordinates, language filters, date ranges, and other criteria."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038b0eda-f034-4c4d-9700-6dd539b485e3",
   "metadata": {},
   "source": [
    "Similarly, for accessing Facebook data, developers must register and apply for App IDs and Access Tokens through the Graph API Developer Portal - <https://developers.facebook.com/>. After obtaining credentials, they can construct HTTP requests to fetch posts, comments, likes, shares, reactions, groups, events, ads, page interactions, metrics, and insights based on specified conditions. Both Twitter and Facebook APIs allow filtering results based on diverse categories and dimensions, enabling users to collect focused datasets with ease."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4017e091-79e5-428b-bc25-6e32c9ddaf25",
   "metadata": {},
   "source": [
    "## Example: Extracting Data from Twitter Using APIs\n",
    "Here are some general steps for extracting data from Twitter using APIs:\n",
    "\n",
    "1. Register a free Twitter developer account on the official developer portal: https://developer.twitter.com/. Follow the instructions provided on the site to complete registration.\n",
    "2. Create an app within your developer account. This will give you access to unique API keys that enable authentication between the Twitter platform and your application. \n",
    "3. Obtain API Keys and Access Token: You will need to generate API keys and access tokens for your application. The API keys will be required when calling the API, while the access token will grant permission for your application to access protected resources, such as private tweets.\n",
    "4. Determine which type of data you want to extract: Before you begin extracting data, consider what kind of data you want to extract. Are you looking for all tweets related to a particular keyword? Do you want to filter tweets based on location, author, language, or any other parameter available through the Twitter API? Knowing what you want ahead of time will save you time and effort later on.\n",
    "5. Set up the query URL: Using the Twitter search API, you can build URLs to retrieve tweets matching specific criteria. Your query string should contain parameters like q (keyword), lang (language), since (date range), until (end date), etc. Depending on the complexity of your query, you may need to test various combinations of parameters to get desired results.\n",
    "6. Retrieve Data: Send HTTP GET requests to Twitter API endpoints and pass along your customized query strings. You can use Python, Java, R, Ruby or whichever programming language you prefer, but ensure that your chosen library has Twitter API integration support. We will use Python in the examples of this project.\n",
    "7. Collect the returned JSON data and parse it to store the results in your database or do further processing.\n",
    "7. Handle Errors: Like most modern APIs, Twitter search API returns error messages if something goes wrong. You'll want to handle those gracefully in your code so that you know what went wrong and why. This way you can iterate and fix problems more easily."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db792008-c582-4405-86c4-758c0b9a318b",
   "metadata": {},
   "source": [
    "## Example: Extracting Data from Twitter Using APIs\n",
    "Here are some general steps for extracting data from Twitter using APIs:\n",
    "\n",
    "1. Register a free Twitter developer account on the official developer portal: https://developer.twitter.com/. Follow the instructions provided on the site to complete registration.\n",
    "2. Create an app within your developer account. This will give you access to unique API keys that enable authentication between the Twitter platform and your application. \n",
    "3. Obtain API Keys and Access Token: You will need to generate API keys and access tokens for your application. The API keys will be required when calling the API, while the access token will grant permission for your application to access protected resources, such as private tweets.\n",
    "4. Determine which type of data you want to extract: Before you begin extracting data, consider what kind of data you want to extract. Are you looking for all tweets related to a particular keyword? Do you want to filter tweets based on location, author, language, or any other parameter available through the Twitter API? Knowing what you want ahead of time will save you time and effort later on.\n",
    "5. Set up the query URL: Using the Twitter search API, you can build URLs to retrieve tweets matching specific criteria. Your query string should contain parameters like q (keyword), lang (language), since (date range), until (end date), etc. Depending on the complexity of your query, you may need to test various combinations of parameters to get desired results.\n",
    "6. Retrieve Data: Send HTTP GET requests to Twitter API endpoints and pass along your customized query strings. You can use Python, Java, R, Ruby or whichever programming language you prefer, but ensure that your chosen library has Twitter API integration support. We will use Python in the examples of this project.\n",
    "7. Collect the returned JSON data and parse it to store the results in your database or do further processing.\n",
    "7. Handle Errors: Like most modern APIs, Twitter search API returns error messages if something goes wrong. You'll want to handle those gracefully in your code so that you know what went wrong and why. This way you can iterate and fix problems more easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1fb982-442c-40fe-98ae-0d3c570b3728",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}